{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundNet, self).__init__()\n",
    "\n",
    "        self.conv1      = nn.Conv1d(1, 16, 64, stride=2, padding=32)\n",
    "        print(\"Conv1\", self.conv1.weight.shape, self.conv1.bias.shape)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "        print(\"Bn1\", self.batchnorm1.weight.shape, self.batchnorm1.bias.shape)\n",
    "        self.relu1      = nn.ReLU(True)\n",
    "        self.maxpool1   = nn.MaxPool1d(8, stride=8)\n",
    "\n",
    "        self.conv2      = nn.Conv1d(16, 32, 32, stride=2, padding=16)\n",
    "        print(\"Conv2\", self.conv2.weight.shape, self.conv2.bias.shape)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        print(\"Bn2\", self.batchnorm2.weight.shape, self.batchnorm2.bias.shape)\n",
    "        self.relu2      = nn.ReLU(True)\n",
    "        self.maxpool2   = nn.MaxPool1d(8, stride=8)\n",
    "\n",
    "        self.conv3      = nn.Conv1d(32, 64, 16, stride=2, padding=8)\n",
    "        print(\"Conv3\", self.conv3.weight.shape, self.conv3.bias.shape)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        print(\"Bn3\", self.batchnorm3.weight.shape, self.batchnorm3.bias.shape)\n",
    "        self.relu3      = nn.ReLU(True)\n",
    "\n",
    "        self.conv4      = nn.Conv1d(64, 128, 8, stride=2, padding=4)\n",
    "        print(\"Conv4\", self.conv4.weight.shape, self.conv4.bias.shape)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "        print(\"Bn4\", self.batchnorm4.weight.shape, self.batchnorm4.bias.shape)\n",
    "        self.relu4      = nn.ReLU(True)\n",
    "\n",
    "        self.conv5      = nn.Conv1d(128, 256, 4, stride=2, padding=2)\n",
    "        print(\"Conv5\", self.conv5.weight.shape, self.conv5.bias.shape)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(256)\n",
    "        print(\"Bn5\", self.batchnorm5.weight.shape, self.batchnorm5.bias.shape)\n",
    "        self.relu5      = nn.ReLU(True)\n",
    "        self.maxpool5   = nn.MaxPool1d(4, stride=4)\n",
    "\n",
    "        self.conv6      = nn.Conv1d(256, 512, 4, stride=2, padding=2)\n",
    "        print(\"Conv6\", self.conv6.weight.shape, self.conv6.bias.shape)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(512)\n",
    "        print(\"Bn6\", self.batchnorm6.weight.shape, self.batchnorm6.bias.shape)\n",
    "        self.relu6      = nn.ReLU(True)\n",
    "\n",
    "        self.conv7      = nn.Conv1d(512, 1024, 4, stride=2, padding=2)\n",
    "        print(\"Conv7\", self.conv7.weight.shape, self.conv7.bias.shape)\n",
    "        self.batchnorm7 = nn.BatchNorm1d(1024)\n",
    "        print(\"Bn7\", self.batchnorm7.weight.shape, self.batchnorm7.bias.shape)\n",
    "        self.relu7      = nn.ReLU(True)\n",
    "\n",
    "        # replace the last layer\n",
    "#         self.conv8_objs = nn.Conv1d(1024, 1000, 8, stride=2)\n",
    "#         print(\"Conv81\", self.conv8_objs.weight.shape, self.conv8_objs.bias.shape)\n",
    "#         self.conv8_scns = nn.Conv1d(1024, 401,  8, stride=2)\n",
    "#         print(\"Conv82\", self.conv8_scns.weight.shape, self.conv8_scns.bias.shape)\n",
    "\n",
    "        self.conv8      = nn.Conv1d(1024, 256, 8)\n",
    "        print(\"Conv8\", self.conv8.weight.shape, self.conv8.bias.shape)\n",
    "#         self.batchnorm8 = nn.BatchNorm1d(256)\n",
    "#         print(\"Bn8\", self.batchnorm8.weight.shape, self.batchnorm8.bias.shape)\n",
    "        self.relu8      = nn.ReLU(True) \n",
    "    \n",
    "    \n",
    "    def forward(self, waveform):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                waveform (Variable): Raw 10s waveform.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            waveform.cuda()\n",
    "\n",
    "        print(\"Size of input: \", waveform.size())\n",
    "        out = self.conv1(waveform)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        print(\"Size after layer 1: \", out.size())\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        print(\"Size after layer 2: \", out.size())\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = self.relu3(out)\n",
    "        print(\"Size after layer 3: \", out.size())\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.batchnorm4(out)\n",
    "        out = self.relu4(out)\n",
    "        print(\"Size after layer 4: \", out.size())\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = self.batchnorm5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.maxpool5(out)\n",
    "        print(\"Size after layer 5: \", out.size())\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = self.batchnorm6(out)\n",
    "        out = self.relu6(out)\n",
    "        print(\"Size after layer 6: \", out.size())\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        out = self.batchnorm7(out)\n",
    "        out = self.relu7(out)\n",
    "        print(\"Size after layer 7: \", out.size())\n",
    "\n",
    "        # replace\n",
    "#         p_objs = self.conv8_objs(out)\n",
    "#         p_scns = self.conv8_scns(out)\n",
    "#         print(\"Size after OBJS: \", p_objs.size())\n",
    "#         print(\"Size after SCNS: \", p_scns.size())\n",
    "\n",
    "#         return (nn.Softmax(dim=1)(p_objs), nn.Softmax(dim=1)(p_scns))\n",
    "            \n",
    "        out = self.conv8(out)\n",
    "        #out = self.batchnorm8(out)\n",
    "        out = self.relu8(out)\n",
    "        print(\"Size after layer 8: \", out.size())\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    def load_weights(self):\n",
    "        bn1_bs = np.load('bn1_bs.npy')\n",
    "        self.batchnorm1.bias = torch.nn.Parameter(torch.from_numpy(bn1_bs))\n",
    "        bn1_ws = np.load('bn1_ws.npy')\n",
    "        self.batchnorm1.weight = torch.nn.Parameter(torch.from_numpy(bn1_ws))\n",
    "        bn2_bs = np.load('bn2_bs.npy')\n",
    "        self.batchnorm2.bias = torch.nn.Parameter(torch.from_numpy(bn2_bs))\n",
    "        bn2_ws = np.load('bn2_ws.npy')\n",
    "        self.batchnorm2.weight = torch.nn.Parameter(torch.from_numpy(bn2_ws))\n",
    "        bn3_bs = np.load('bn3_bs.npy')\n",
    "        self.batchnorm3.bias = torch.nn.Parameter(torch.from_numpy(bn3_bs))\n",
    "        bn3_ws = np.load('bn3_ws.npy')\n",
    "        self.batchnorm3.weight = torch.nn.Parameter(torch.from_numpy(bn3_ws))\n",
    "        bn4_bs = np.load('bn4_bs.npy')\n",
    "        self.batchnorm4.bias = torch.nn.Parameter(torch.from_numpy(bn4_bs))\n",
    "        bn4_ws = np.load('bn4_ws.npy')\n",
    "        self.batchnorm4.weight = torch.nn.Parameter(torch.from_numpy(bn4_ws))\n",
    "        bn5_bs = np.load('bn5_bs.npy')\n",
    "        self.batchnorm5.bias = torch.nn.Parameter(torch.from_numpy(bn5_bs))\n",
    "        bn5_ws = np.load('bn5_ws.npy')\n",
    "        self.batchnorm5.weight = torch.nn.Parameter(torch.from_numpy(bn5_ws))\n",
    "        bn6_bs = np.load('bn6_bs.npy')\n",
    "        self.batchnorm6.bias = torch.nn.Parameter(torch.from_numpy(bn6_bs))\n",
    "        bn6_ws = np.load('bn6_ws.npy')\n",
    "        self.batchnorm6.weight = torch.nn.Parameter(torch.from_numpy(bn6_ws))\n",
    "        bn7_bs = np.load('bn7_bs.npy')\n",
    "        self.batchnorm7.bias = torch.nn.Parameter(torch.from_numpy(bn7_bs))\n",
    "        bn7_ws = np.load('bn7_ws.npy')\n",
    "        self.batchnorm7.weight = torch.nn.Parameter(torch.from_numpy(bn7_ws))\n",
    "\n",
    "        conv1_bs = np.load('conv1_bs.npy')\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(conv1_bs))\n",
    "        conv1_ws = np.load('conv1_ws.npy')\n",
    "        conv1_ws = np.reshape(conv1_ws, self.conv1.weight.shape)\n",
    "        self.conv1.weight = torch.nn.Parameter(torch.from_numpy(conv1_ws))\n",
    "\n",
    "        conv2_bs = np.load('conv2_bs.npy')\n",
    "        self.conv2.bias = torch.nn.Parameter(torch.from_numpy(conv2_bs))\n",
    "        conv2_ws = np.load('conv2_ws.npy')\n",
    "        conv2_ws = np.reshape(conv2_ws, self.conv2.weight.shape)\n",
    "        self.conv2.weight = torch.nn.Parameter(torch.from_numpy(conv2_ws))\n",
    "\n",
    "        conv3_bs = np.load('conv3_bs.npy')\n",
    "        self.conv3.bias = torch.nn.Parameter(torch.from_numpy(conv3_bs))\n",
    "        conv3_ws = np.load('conv3_ws.npy')\n",
    "        conv3_ws = np.reshape(conv3_ws, self.conv3.weight.shape)\n",
    "        self.conv3.weight = torch.nn.Parameter(torch.from_numpy(conv3_ws))\n",
    "\n",
    "        conv4_bs = np.load('conv4_bs.npy')\n",
    "        self.conv4.bias = torch.nn.Parameter(torch.from_numpy(conv4_bs))\n",
    "        conv4_ws = np.load('conv4_ws.npy')\n",
    "        conv4_ws = np.reshape(conv4_ws, self.conv4.weight.shape)\n",
    "        self.conv4.weight = torch.nn.Parameter(torch.from_numpy(conv4_ws))\n",
    "\n",
    "        conv5_bs = np.load('conv5_bs.npy')\n",
    "        self.conv5.bias = torch.nn.Parameter(torch.from_numpy(conv5_bs))\n",
    "        conv5_ws = np.load('conv5_ws.npy')\n",
    "        conv5_ws = np.reshape(conv5_ws, self.conv5.weight.shape)\n",
    "        self.conv5.weight = torch.nn.Parameter(torch.from_numpy(conv5_ws))\n",
    "\n",
    "        conv6_bs = np.load('conv6_bs.npy')\n",
    "        self.conv6.bias = torch.nn.Parameter(torch.from_numpy(conv6_bs))\n",
    "        conv6_ws = np.load('conv6_ws.npy')\n",
    "        conv6_ws = np.reshape(conv6_ws, self.conv6.weight.shape)\n",
    "        self.conv6.weight = torch.nn.Parameter(torch.from_numpy(conv6_ws))\n",
    "\n",
    "        conv7_bs = np.load('conv7_bs.npy')\n",
    "        self.conv7.bias = torch.nn.Parameter(torch.from_numpy(conv7_bs))\n",
    "        conv7_ws = np.load('conv7_ws.npy')\n",
    "        conv7_ws = np.reshape(conv7_ws, self.conv7.weight.shape)\n",
    "        self.conv7.weight = torch.nn.Parameter(torch.from_numpy(conv7_ws))\n",
    "\n",
    "        # replace\n",
    "#         conv81_bs = np.load('conv81_bs.npy')\n",
    "#         self.conv8_objs.bias = torch.nn.Parameter(torch.from_numpy(conv81_bs))\n",
    "#         conv81_ws = np.load('conv81_ws.npy')\n",
    "#         conv81_ws = np.reshape(conv81_ws, self.conv8_objs.weight.shape)\n",
    "#         self.conv8_objs.weight = torch.nn.Parameter(torch.from_numpy(conv81_ws))\n",
    "\n",
    "#         conv82_bs = np.load('conv82_bs.npy')\n",
    "#         self.conv8_scns.bias = torch.nn.Parameter(torch.from_numpy(conv82_bs))\n",
    "#         conv82_ws = np.load('conv82_ws.npy')\n",
    "#         conv82_ws = np.reshape(conv82_ws, self.conv8_scns.weight.shape)\n",
    "#         self.conv8_scns.weight = torch.nn.Parameter(torch.from_numpy(conv82_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 torch.Size([16, 1, 64]) torch.Size([16])\n",
      "Bn1 torch.Size([16]) torch.Size([16])\n",
      "Conv2 torch.Size([32, 16, 32]) torch.Size([32])\n",
      "Bn2 torch.Size([32]) torch.Size([32])\n",
      "Conv3 torch.Size([64, 32, 16]) torch.Size([64])\n",
      "Bn3 torch.Size([64]) torch.Size([64])\n",
      "Conv4 torch.Size([128, 64, 8]) torch.Size([128])\n",
      "Bn4 torch.Size([128]) torch.Size([128])\n",
      "Conv5 torch.Size([256, 128, 4]) torch.Size([256])\n",
      "Bn5 torch.Size([256]) torch.Size([256])\n",
      "Conv6 torch.Size([512, 256, 4]) torch.Size([512])\n",
      "Bn6 torch.Size([512]) torch.Size([512])\n",
      "Conv7 torch.Size([1024, 512, 4]) torch.Size([1024])\n",
      "Bn7 torch.Size([1024]) torch.Size([1024])\n",
      "Conv8 torch.Size([256, 1024, 8]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "soundnet = SoundNet()\n",
    "soundnet.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_WAVEFORM = 44100*5\n",
    "import torchaudio\n",
    "data, sample_rate = torchaudio.load('/nfs2/datasets/TED/audio/WadeDavis_2008-480p.mp3')\n",
    "data.size(), sample_rate\n",
    "\n",
    "#data1 = data[:LEN_WAVEFORM]\n",
    "data1 = data[:LEN_WAVEFORM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([220500])\n"
     ]
    }
   ],
   "source": [
    "channel_mean_data1 = torch.mean(data1,dim=1)\n",
    "print(channel_mean_data1.size())\n",
    "# channel_mean_data2 = torch.mean(data2,dim=1)\n",
    "# print(channel_mean_data2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 220500])\n"
     ]
    }
   ],
   "source": [
    "channel_mean_data1 = channel_mean_data1.view(1,1,channel_mean_data1.size(0))\n",
    "print(channel_mean_data1.size())\n",
    "# channel_mean_data2 = channel_mean_data2.view(1,1,channel_mean_data2.size(0))\n",
    "# print(channel_mean_data2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input:  torch.Size([1, 1, 220500])\n",
      "Size after layer 1:  torch.Size([1, 16, 13781])\n",
      "Size after layer 2:  torch.Size([1, 32, 861])\n",
      "Size after layer 3:  torch.Size([1, 64, 431])\n",
      "Size after layer 4:  torch.Size([1, 128, 216])\n",
      "Size after layer 5:  torch.Size([1, 256, 27])\n",
      "Size after layer 6:  torch.Size([1, 512, 14])\n",
      "Size after layer 7:  torch.Size([1, 1024, 8])\n",
      "Size after layer 8:  torch.Size([1, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "output1 = soundnet(channel_mean_data1)\n",
    "# output2 = soundnet(channel_mean_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1])\n",
      "torch.Size([1, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "print(output1.size())\n",
    "print(output1.size())\n",
    "# print(output2[0].size())\n",
    "# print(output2[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoseNet, self).__init__()\n",
    "\n",
    "        self.conv1      = nn.Conv1d(36, 64, 10, stride=1, padding=5)\n",
    "        print(\"Conv1\", self.conv1.weight.shape, self.conv1.bias.shape)    \n",
    "        self.relu1      = nn.ReLU(True)\n",
    "        \n",
    "\n",
    "        self.conv2      = nn.Conv1d(64, 128, 10, stride=1, padding=5)\n",
    "        print(\"Conv2\", self.conv2.weight.shape, self.conv2.bias.shape)\n",
    "        self.relu2      = nn.ReLU(True)\n",
    "        \n",
    "\n",
    "        self.conv3      = nn.Conv1d(128, 256, 10, stride=1, padding=5)\n",
    "        print(\"Conv3\", self.conv3.weight.shape, self.conv3.bias.shape)\n",
    "        self.relu3      = nn.ReLU(True)\n",
    "\n",
    "        \n",
    "        self.conv4      = nn.Conv1d(256, 256, 10, stride=1, padding=5)\n",
    "        print(\"Conv4\", self.conv4.weight.shape, self.conv4.bias.shape)\n",
    "        self.relu4      = nn.ReLU(True)\n",
    "\n",
    "\n",
    "    def forward(self, pose):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                pose (Variable): Raw 10s pose information.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            pose.cuda()\n",
    "\n",
    "        print(\"Size of input: \", pose.size())\n",
    "        out = self.conv1(pose)\n",
    "        #out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "        #out = self.maxpool1(out)\n",
    "        print(\"Size after layer 1: \", out.size())\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        #out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "        #out = self.maxpool2(out)\n",
    "        print(\"Size after layer 2: \", out.size())\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        #out = self.batchnorm3(out)\n",
    "        out = self.relu3(out)\n",
    "        print(\"Size after layer 3: \", out.size())\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        #out = self.batchnorm4(out)\n",
    "        out = self.relu4(out)\n",
    "        print(\"Size after layer 4: \", out.size())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 300])\n"
     ]
    }
   ],
   "source": [
    "posedata = torch.randn(36*300)\n",
    "#posedata.size()\n",
    "posedata = posedata.view(1,36,-1)\n",
    "print(posedata.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 torch.Size([64, 36, 10]) torch.Size([64])\n",
      "Conv2 torch.Size([128, 64, 10]) torch.Size([128])\n",
      "Conv3 torch.Size([256, 128, 10]) torch.Size([256])\n",
      "Conv4 torch.Size([256, 256, 10]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "posenet = PoseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input:  torch.Size([1, 36, 300])\n",
      "Size after layer 1:  torch.Size([1, 64, 301])\n",
      "Size after layer 2:  torch.Size([1, 128, 302])\n",
      "Size after layer 3:  torch.Size([1, 256, 303])\n",
      "Size after layer 4:  torch.Size([1, 256, 304])\n"
     ]
    }
   ],
   "source": [
    "output_pose = posenet(posedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
