{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoundNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundNet, self).__init__()\n",
    "\n",
    "        self.conv1      = nn.Conv1d(1, 16, 64, stride=2, padding=32)\n",
    "        print(\"Conv1\", self.conv1.weight.shape, self.conv1.bias.shape)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "        print(\"Bn1\", self.batchnorm1.weight.shape, self.batchnorm1.bias.shape)\n",
    "        self.relu1      = nn.ReLU(True)\n",
    "        self.maxpool1   = nn.MaxPool1d(8, stride=8)\n",
    "\n",
    "        self.conv2      = nn.Conv1d(16, 32, 32, stride=2, padding=16)\n",
    "        print(\"Conv2\", self.conv2.weight.shape, self.conv2.bias.shape)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "        print(\"Bn2\", self.batchnorm2.weight.shape, self.batchnorm2.bias.shape)\n",
    "        self.relu2      = nn.ReLU(True)\n",
    "        self.maxpool2   = nn.MaxPool1d(8, stride=8)\n",
    "\n",
    "        self.conv3      = nn.Conv1d(32, 64, 16, stride=2, padding=8)\n",
    "        print(\"Conv3\", self.conv3.weight.shape, self.conv3.bias.shape)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        print(\"Bn3\", self.batchnorm3.weight.shape, self.batchnorm3.bias.shape)\n",
    "        self.relu3      = nn.ReLU(True)\n",
    "\n",
    "        self.conv4      = nn.Conv1d(64, 128, 8, stride=2, padding=4)\n",
    "        print(\"Conv4\", self.conv4.weight.shape, self.conv4.bias.shape)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(128)\n",
    "        print(\"Bn4\", self.batchnorm4.weight.shape, self.batchnorm4.bias.shape)\n",
    "        self.relu4      = nn.ReLU(True)\n",
    "\n",
    "        self.conv5      = nn.Conv1d(128, 256, 4, stride=2, padding=2)\n",
    "        print(\"Conv5\", self.conv5.weight.shape, self.conv5.bias.shape)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(256)\n",
    "        print(\"Bn5\", self.batchnorm5.weight.shape, self.batchnorm5.bias.shape)\n",
    "        self.relu5      = nn.ReLU(True)\n",
    "        self.maxpool5   = nn.MaxPool1d(4, stride=4)\n",
    "\n",
    "        self.conv6      = nn.Conv1d(256, 512, 4, stride=2, padding=2)\n",
    "        print(\"Conv6\", self.conv6.weight.shape, self.conv6.bias.shape)\n",
    "        self.batchnorm6 = nn.BatchNorm1d(512)\n",
    "        print(\"Bn6\", self.batchnorm6.weight.shape, self.batchnorm6.bias.shape)\n",
    "        self.relu6      = nn.ReLU(True)\n",
    "\n",
    "        self.conv7      = nn.Conv1d(512, 1024, 4, stride=2, padding=2)\n",
    "        print(\"Conv7\", self.conv7.weight.shape, self.conv7.bias.shape)\n",
    "        self.batchnorm7 = nn.BatchNorm1d(1024)\n",
    "        print(\"Bn7\", self.batchnorm7.weight.shape, self.batchnorm7.bias.shape)\n",
    "        self.relu7      = nn.ReLU(True)\n",
    "\n",
    "        # replace the last layer\n",
    "#         self.conv8_objs = nn.Conv1d(1024, 1000, 8, stride=2)\n",
    "#         print(\"Conv81\", self.conv8_objs.weight.shape, self.conv8_objs.bias.shape)\n",
    "#         self.conv8_scns = nn.Conv1d(1024, 401,  8, stride=2)\n",
    "#         print(\"Conv82\", self.conv8_scns.weight.shape, self.conv8_scns.bias.shape)\n",
    "\n",
    "        self.conv8      = nn.Conv1d(1024, 256, 8)\n",
    "        print(\"Conv8\", self.conv8.weight.shape, self.conv8.bias.shape)\n",
    "#         self.batchnorm8 = nn.BatchNorm1d(256)\n",
    "#         print(\"Bn8\", self.batchnorm8.weight.shape, self.batchnorm8.bias.shape)\n",
    "        self.relu8      = nn.ReLU(True) \n",
    "    \n",
    "    \n",
    "    def forward(self, waveform):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                waveform (Variable): Raw 10s waveform.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            waveform.cuda()\n",
    "\n",
    "        print(\"Size of input: \", waveform.size())\n",
    "        out = self.conv1(waveform)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        print(\"Size after layer 1: \", out.size())\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        print(\"Size after layer 2: \", out.size())\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = self.relu3(out)\n",
    "        print(\"Size after layer 3: \", out.size())\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.batchnorm4(out)\n",
    "        out = self.relu4(out)\n",
    "        print(\"Size after layer 4: \", out.size())\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = self.batchnorm5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.maxpool5(out)\n",
    "        print(\"Size after layer 5: \", out.size())\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = self.batchnorm6(out)\n",
    "        out = self.relu6(out)\n",
    "        print(\"Size after layer 6: \", out.size())\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        out = self.batchnorm7(out)\n",
    "        out = self.relu7(out)\n",
    "        print(\"Size after layer 7: \", out.size())\n",
    "\n",
    "        # replace\n",
    "#         p_objs = self.conv8_objs(out)\n",
    "#         p_scns = self.conv8_scns(out)\n",
    "#         print(\"Size after OBJS: \", p_objs.size())\n",
    "#         print(\"Size after SCNS: \", p_scns.size())\n",
    "\n",
    "#         return (nn.Softmax(dim=1)(p_objs), nn.Softmax(dim=1)(p_scns))\n",
    "            \n",
    "        out = self.conv8(out)\n",
    "        #out = self.batchnorm8(out)\n",
    "        out = self.relu8(out)\n",
    "        print(\"Size after layer 8: \", out.size())\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "    def load_weights(self):\n",
    "        bn1_bs = np.load('bn1_bs.npy')\n",
    "        self.batchnorm1.bias = torch.nn.Parameter(torch.from_numpy(bn1_bs))\n",
    "        bn1_ws = np.load('bn1_ws.npy')\n",
    "        self.batchnorm1.weight = torch.nn.Parameter(torch.from_numpy(bn1_ws))\n",
    "        bn2_bs = np.load('bn2_bs.npy')\n",
    "        self.batchnorm2.bias = torch.nn.Parameter(torch.from_numpy(bn2_bs))\n",
    "        bn2_ws = np.load('bn2_ws.npy')\n",
    "        self.batchnorm2.weight = torch.nn.Parameter(torch.from_numpy(bn2_ws))\n",
    "        bn3_bs = np.load('bn3_bs.npy')\n",
    "        self.batchnorm3.bias = torch.nn.Parameter(torch.from_numpy(bn3_bs))\n",
    "        bn3_ws = np.load('bn3_ws.npy')\n",
    "        self.batchnorm3.weight = torch.nn.Parameter(torch.from_numpy(bn3_ws))\n",
    "        bn4_bs = np.load('bn4_bs.npy')\n",
    "        self.batchnorm4.bias = torch.nn.Parameter(torch.from_numpy(bn4_bs))\n",
    "        bn4_ws = np.load('bn4_ws.npy')\n",
    "        self.batchnorm4.weight = torch.nn.Parameter(torch.from_numpy(bn4_ws))\n",
    "        bn5_bs = np.load('bn5_bs.npy')\n",
    "        self.batchnorm5.bias = torch.nn.Parameter(torch.from_numpy(bn5_bs))\n",
    "        bn5_ws = np.load('bn5_ws.npy')\n",
    "        self.batchnorm5.weight = torch.nn.Parameter(torch.from_numpy(bn5_ws))\n",
    "        bn6_bs = np.load('bn6_bs.npy')\n",
    "        self.batchnorm6.bias = torch.nn.Parameter(torch.from_numpy(bn6_bs))\n",
    "        bn6_ws = np.load('bn6_ws.npy')\n",
    "        self.batchnorm6.weight = torch.nn.Parameter(torch.from_numpy(bn6_ws))\n",
    "        bn7_bs = np.load('bn7_bs.npy')\n",
    "        self.batchnorm7.bias = torch.nn.Parameter(torch.from_numpy(bn7_bs))\n",
    "        bn7_ws = np.load('bn7_ws.npy')\n",
    "        self.batchnorm7.weight = torch.nn.Parameter(torch.from_numpy(bn7_ws))\n",
    "\n",
    "        conv1_bs = np.load('conv1_bs.npy')\n",
    "        self.conv1.bias = torch.nn.Parameter(torch.from_numpy(conv1_bs))\n",
    "        conv1_ws = np.load('conv1_ws.npy')\n",
    "        conv1_ws = np.reshape(conv1_ws, self.conv1.weight.shape)\n",
    "        self.conv1.weight = torch.nn.Parameter(torch.from_numpy(conv1_ws))\n",
    "\n",
    "        conv2_bs = np.load('conv2_bs.npy')\n",
    "        self.conv2.bias = torch.nn.Parameter(torch.from_numpy(conv2_bs))\n",
    "        conv2_ws = np.load('conv2_ws.npy')\n",
    "        conv2_ws = np.reshape(conv2_ws, self.conv2.weight.shape)\n",
    "        self.conv2.weight = torch.nn.Parameter(torch.from_numpy(conv2_ws))\n",
    "\n",
    "        conv3_bs = np.load('conv3_bs.npy')\n",
    "        self.conv3.bias = torch.nn.Parameter(torch.from_numpy(conv3_bs))\n",
    "        conv3_ws = np.load('conv3_ws.npy')\n",
    "        conv3_ws = np.reshape(conv3_ws, self.conv3.weight.shape)\n",
    "        self.conv3.weight = torch.nn.Parameter(torch.from_numpy(conv3_ws))\n",
    "\n",
    "        conv4_bs = np.load('conv4_bs.npy')\n",
    "        self.conv4.bias = torch.nn.Parameter(torch.from_numpy(conv4_bs))\n",
    "        conv4_ws = np.load('conv4_ws.npy')\n",
    "        conv4_ws = np.reshape(conv4_ws, self.conv4.weight.shape)\n",
    "        self.conv4.weight = torch.nn.Parameter(torch.from_numpy(conv4_ws))\n",
    "\n",
    "        conv5_bs = np.load('conv5_bs.npy')\n",
    "        self.conv5.bias = torch.nn.Parameter(torch.from_numpy(conv5_bs))\n",
    "        conv5_ws = np.load('conv5_ws.npy')\n",
    "        conv5_ws = np.reshape(conv5_ws, self.conv5.weight.shape)\n",
    "        self.conv5.weight = torch.nn.Parameter(torch.from_numpy(conv5_ws))\n",
    "\n",
    "        conv6_bs = np.load('conv6_bs.npy')\n",
    "        self.conv6.bias = torch.nn.Parameter(torch.from_numpy(conv6_bs))\n",
    "        conv6_ws = np.load('conv6_ws.npy')\n",
    "        conv6_ws = np.reshape(conv6_ws, self.conv6.weight.shape)\n",
    "        self.conv6.weight = torch.nn.Parameter(torch.from_numpy(conv6_ws))\n",
    "\n",
    "        conv7_bs = np.load('conv7_bs.npy')\n",
    "        self.conv7.bias = torch.nn.Parameter(torch.from_numpy(conv7_bs))\n",
    "        conv7_ws = np.load('conv7_ws.npy')\n",
    "        conv7_ws = np.reshape(conv7_ws, self.conv7.weight.shape)\n",
    "        self.conv7.weight = torch.nn.Parameter(torch.from_numpy(conv7_ws))\n",
    "\n",
    "        # replace\n",
    "#         conv81_bs = np.load('conv81_bs.npy')\n",
    "#         self.conv8_objs.bias = torch.nn.Parameter(torch.from_numpy(conv81_bs))\n",
    "#         conv81_ws = np.load('conv81_ws.npy')\n",
    "#         conv81_ws = np.reshape(conv81_ws, self.conv8_objs.weight.shape)\n",
    "#         self.conv8_objs.weight = torch.nn.Parameter(torch.from_numpy(conv81_ws))\n",
    "\n",
    "#         conv82_bs = np.load('conv82_bs.npy')\n",
    "#         self.conv8_scns.bias = torch.nn.Parameter(torch.from_numpy(conv82_bs))\n",
    "#         conv82_ws = np.load('conv82_ws.npy')\n",
    "#         conv82_ws = np.reshape(conv82_ws, self.conv8_scns.weight.shape)\n",
    "#         self.conv8_scns.weight = torch.nn.Parameter(torch.from_numpy(conv82_ws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 torch.Size([16, 1, 64]) torch.Size([16])\n",
      "Bn1 torch.Size([16]) torch.Size([16])\n",
      "Conv2 torch.Size([32, 16, 32]) torch.Size([32])\n",
      "Bn2 torch.Size([32]) torch.Size([32])\n",
      "Conv3 torch.Size([64, 32, 16]) torch.Size([64])\n",
      "Bn3 torch.Size([64]) torch.Size([64])\n",
      "Conv4 torch.Size([128, 64, 8]) torch.Size([128])\n",
      "Bn4 torch.Size([128]) torch.Size([128])\n",
      "Conv5 torch.Size([256, 128, 4]) torch.Size([256])\n",
      "Bn5 torch.Size([256]) torch.Size([256])\n",
      "Conv6 torch.Size([512, 256, 4]) torch.Size([512])\n",
      "Bn6 torch.Size([512]) torch.Size([512])\n",
      "Conv7 torch.Size([1024, 512, 4]) torch.Size([1024])\n",
      "Bn7 torch.Size([1024]) torch.Size([1024])\n",
      "Conv8 torch.Size([256, 1024, 8]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "soundnet = SoundNet()\n",
    "soundnet.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_WAVEFORM = 44100*5\n",
    "import torchaudio\n",
    "data, sample_rate = torchaudio.load('/nfs2/datasets/TED/audio/WadeDavis_2008-480p.mp3')\n",
    "data.size(), sample_rate\n",
    "\n",
    "#data1 = data[:LEN_WAVEFORM]\n",
    "data1 = data[:LEN_WAVEFORM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([220500])\n"
     ]
    }
   ],
   "source": [
    "channel_mean_data1 = torch.mean(data1,dim=1)\n",
    "print(channel_mean_data1.size())\n",
    "# channel_mean_data2 = torch.mean(data2,dim=1)\n",
    "# print(channel_mean_data2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 220500])\n"
     ]
    }
   ],
   "source": [
    "channel_mean_data1 = channel_mean_data1.view(1,1,channel_mean_data1.size(0))\n",
    "print(channel_mean_data1.size())\n",
    "# channel_mean_data2 = channel_mean_data2.view(1,1,channel_mean_data2.size(0))\n",
    "# print(channel_mean_data2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input:  torch.Size([1, 1, 220500])\n",
      "Size after layer 1:  torch.Size([1, 16, 13781])\n",
      "Size after layer 2:  torch.Size([1, 32, 861])\n",
      "Size after layer 3:  torch.Size([1, 64, 431])\n",
      "Size after layer 4:  torch.Size([1, 128, 216])\n",
      "Size after layer 5:  torch.Size([1, 256, 27])\n",
      "Size after layer 6:  torch.Size([1, 512, 14])\n",
      "Size after layer 7:  torch.Size([1, 1024, 8])\n",
      "Size after layer 8:  torch.Size([1, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "output1 = soundnet(channel_mean_data1)\n",
    "# output2 = soundnet(channel_mean_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 1])\n",
      "torch.Size([1, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "print(output1.size())\n",
    "print(output1.size())\n",
    "# print(output2[0].size())\n",
    "# print(output2[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoseNet, self).__init__()\n",
    "\n",
    "        self.conv1      = nn.Conv1d(36, 64, 10, stride=1, padding=5)\n",
    "        print(\"Conv1\", self.conv1.weight.shape, self.conv1.bias.shape)    \n",
    "        self.relu1      = nn.ReLU(True)\n",
    "        \n",
    "\n",
    "        self.conv2      = nn.Conv1d(64, 128, 10, stride=1, padding=5)\n",
    "        print(\"Conv2\", self.conv2.weight.shape, self.conv2.bias.shape)\n",
    "        self.relu2      = nn.ReLU(True)\n",
    "        \n",
    "\n",
    "        self.conv3      = nn.Conv1d(128, 256, 10, stride=1, padding=5)\n",
    "        print(\"Conv3\", self.conv3.weight.shape, self.conv3.bias.shape)\n",
    "        self.relu3      = nn.ReLU(True)\n",
    "\n",
    "        \n",
    "        self.conv4      = nn.Conv1d(256, 256, 10, stride=1, padding=5)\n",
    "        print(\"Conv4\", self.conv4.weight.shape, self.conv4.bias.shape)\n",
    "        self.relu4      = nn.ReLU(True)\n",
    "\n",
    "\n",
    "    def forward(self, pose):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                pose (Variable): Raw 10s pose information.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            pose.cuda()\n",
    "\n",
    "        print(\"Size of input: \", pose.size())\n",
    "        out = self.conv1(pose)\n",
    "        #out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "        #out = self.maxpool1(out)\n",
    "        print(\"Size after layer 1: \", out.size())\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        #out = self.batchnorm2(out)\n",
    "        out = self.relu2(out)\n",
    "        #out = self.maxpool2(out)\n",
    "        print(\"Size after layer 2: \", out.size())\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        #out = self.batchnorm3(out)\n",
    "        out = self.relu3(out)\n",
    "        print(\"Size after layer 3: \", out.size())\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        #out = self.batchnorm4(out)\n",
    "        out = self.relu4(out)\n",
    "        print(\"Size after layer 4: \", out.size())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 300])\n"
     ]
    }
   ],
   "source": [
    "posedata = torch.randn(36*300)\n",
    "#posedata.size()\n",
    "posedata = posedata.view(1,36,-1)\n",
    "print(posedata.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 torch.Size([64, 36, 10]) torch.Size([64])\n",
      "Conv2 torch.Size([128, 64, 10]) torch.Size([128])\n",
      "Conv3 torch.Size([256, 128, 10]) torch.Size([256])\n",
      "Conv4 torch.Size([256, 256, 10]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "posenet = PoseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input:  torch.Size([1, 36, 300])\n",
      "Size after layer 1:  torch.Size([1, 64, 301])\n",
      "Size after layer 2:  torch.Size([1, 128, 302])\n",
      "Size after layer 3:  torch.Size([1, 256, 303])\n",
      "Size after layer 4:  torch.Size([1, 256, 304])\n"
     ]
    }
   ],
   "source": [
    "output_pose = posenet(posedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -framerate 30 -start_number 15481 -i /nfs2/datasets/TED/frames/AaronKoblin_2011-480p/%6d.jpg -vframes 150 -pix_fmt yuv420p -codec:v libx264 -y /nfs1/shared/for_aniruddha/regenerate_video_0003.mp4\n",
      "ffmpeg -loglevel error -i /nfs1/shared/for_aniruddha/regenerate_video_0003.mp4 -i /nfs1/shared/for_aniruddha/pose/dataset/audios/AaronKoblin_2011-480p_0002.mp3 -c:v copy -r 30 -c:a copy -strict experimental -y /nfs1/shared/for_aniruddha/regenerate_final_0003.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "pose_only_frame_root = '/nfs2/datasets/TED/frames/AaronKoblin_2011-480p'\n",
    "audiopath = '/nfs1/shared/for_aniruddha/pose/dataset/audios/AaronKoblin_2011-480p_0002.mp3'\n",
    "store_path = '/nfs1/shared/for_aniruddha/regenerate_final_0003.mp4'\n",
    "clip_video_path = '/nfs1/shared/for_aniruddha/regenerate_video_0003.mp4'\n",
    "sequence_start_frame = \"15481\"\n",
    "\n",
    "\n",
    "bash_command_video = \"ffmpeg -framerate 30 -start_number \" + sequence_start_frame + \" -i \" + pose_only_frame_root + \"/%6d.jpg -vframes 150 -pix_fmt yuv420p -codec:v libx264 -y \" + clip_video_path\n",
    "print(bash_command_video)\n",
    "\n",
    "subprocess.call(bash_command_video.split(' '))\n",
    "\n",
    "bash_command1 = \"ffmpeg -loglevel error -i \" + clip_video_path + \" -i \" + audiopath + \" -c:v copy -r 30 -c:a copy -strict experimental -y \" + store_path\n",
    "print(bash_command1)\n",
    "\n",
    "subprocess.call(bash_command1.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7efcf950c410>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posenet.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-0.9049,  4.3081, -3.8603,  ..., -0.8333,  3.5384, -0.2840],\n",
      "         [ 0.4630, -4.3452,  1.6706,  ...,  1.8270, -0.1649,  0.5262],\n",
      "         [-1.5739, -3.2794,  2.9341,  ..., -2.1455, -2.2507, -4.0957],\n",
      "         ...,\n",
      "         [ 1.2406,  3.0575,  3.0486,  ...,  5.2100, -2.9382, -1.0612],\n",
      "         [ 2.9407,  3.3743, -2.8915,  ..., -0.1833, -0.6028, -5.0985],\n",
      "         [-2.9811,  1.8573,  2.4196,  ...,  2.2074, -2.5085,  2.7064]],\n",
      "\n",
      "        [[-4.0294,  3.7837, -3.4412,  ...,  3.7236, -5.1823,  1.4328],\n",
      "         [ 1.1438, -3.9206,  3.2194,  ..., -3.6679, -4.3261,  2.5304],\n",
      "         [ 0.2853, -2.2933,  1.4477,  ...,  1.3271,  4.5030, -4.1439],\n",
      "         ...,\n",
      "         [ 1.0300,  0.2102, -3.2962,  ..., -4.9533, -4.3075,  4.7745],\n",
      "         [-2.8435, -3.4318, -0.6136,  ..., -2.9708,  0.7202, -4.2107],\n",
      "         [ 1.8962,  2.6117, -3.0563,  ..., -1.6439,  4.5801,  0.3899]],\n",
      "\n",
      "        [[ 2.3897, -3.9763,  3.8594,  ...,  1.7878,  1.5926,  1.6265],\n",
      "         [ 2.0838,  3.0424,  1.3981,  ..., -3.5079,  0.0589,  1.5257],\n",
      "         [-3.9732,  0.5199,  0.4181,  ..., -1.7964, -3.4556, -4.8450],\n",
      "         ...,\n",
      "         [-2.0381, -4.2900, -3.3664,  ...,  0.0111,  0.7688, -5.0350],\n",
      "         [ 0.1238, -1.6714,  1.1066,  ...,  2.3147,  3.3517, -3.7750],\n",
      "         [ 2.9737, -1.1404, -3.2849,  ...,  3.9109, -0.6264, -2.7615]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.0423, -1.2075, -3.9911,  ..., -0.6407, -1.0272, -1.4064],\n",
      "         [-2.9657,  3.5114,  4.2426,  ..., -2.3671,  3.9226, -0.1817],\n",
      "         [-4.3226,  1.1110, -5.0248,  ..., -1.8190, -4.9916,  3.3858],\n",
      "         ...,\n",
      "         [-3.8972, -3.1811,  2.5923,  ...,  2.8402,  1.4725,  2.3413],\n",
      "         [-1.2489,  3.6734,  3.3126,  ..., -0.0461,  1.4315,  1.4690],\n",
      "         [ 3.5836, -1.4990, -1.2443,  ..., -1.3532, -3.7599, -1.3157]],\n",
      "\n",
      "        [[-3.7220, -3.5502, -3.3576,  ..., -4.2379,  3.2836,  4.5324],\n",
      "         [-4.8230,  3.4192, -2.4005,  ..., -2.8531,  1.4971, -1.4225],\n",
      "         [-0.4237, -3.6274,  2.2111,  ...,  2.7936,  5.1580, -2.7956],\n",
      "         ...,\n",
      "         [ 4.6155, -3.9438,  1.7663,  ...,  2.2275,  2.7265, -1.8221],\n",
      "         [-3.0374,  3.0260,  2.0607,  ..., -5.1066, -0.9714, -4.4561],\n",
      "         [ 0.8748,  1.1785, -3.1744,  ..., -2.1540,  0.5798,  0.3884]],\n",
      "\n",
      "        [[-0.3567,  4.8770, -0.9091,  ..., -0.3025,  0.6490,  2.0861],\n",
      "         [ 4.0336,  1.0850,  3.1333,  ..., -3.5932, -4.5972, -1.8975],\n",
      "         [-0.6590,  4.3085,  3.6776,  ...,  0.6038, -3.5522,  0.2290],\n",
      "         ...,\n",
      "         [-2.3234,  3.3311, -1.1044,  ...,  1.1048,  1.3471, -0.5392],\n",
      "         [ 3.7070, -0.5593,  3.6457,  ...,  1.6816, -1.2550, -1.2535],\n",
      "         [-2.7224,  2.9370, -2.4251,  ..., -0.3343, -1.6332,  2.8747]]])\n",
      "conv1.bias\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-1.4301,  0.6395, -0.1612,  0.1009,  3.8089, -0.2252,  1.7852,\n",
      "         1.3380, -3.0939,  1.0909, -1.7792,  5.2417,  0.7926, -2.1364,\n",
      "         3.4905, -4.9729, -1.9385, -3.6743, -1.1284, -1.9423, -1.9305,\n",
      "         2.3818,  2.4041,  0.4587,  3.6640, -0.0102, -4.8445, -2.3068,\n",
      "         0.8501, -1.6543,  1.9915, -0.5185, -0.2373, -2.4063,  0.1830,\n",
      "        -3.4715,  4.4638, -2.8827, -2.8507, -0.2094, -1.8841,  3.2782,\n",
      "         1.7392,  0.5053, -0.8539,  1.5053,  3.8490, -2.2108,  2.1601,\n",
      "         2.1667, -5.2162,  1.3739, -0.0041, -3.5193, -0.4250,  3.3318,\n",
      "         4.0948,  1.8502,  4.7655, -2.6830,  4.3913,  2.2817,  1.4741,\n",
      "         4.7810])\n",
      "conv2.weight\n",
      "Parameter containing:\n",
      "tensor([[[-1.9276e-02, -2.9971e-02, -3.2706e-02,  ...,  3.9501e-02,\n",
      "           3.1046e-02,  1.9465e-02],\n",
      "         [-1.3710e-02,  3.0519e-02,  2.6743e-02,  ..., -9.3192e-03,\n",
      "           2.0636e-02,  1.4639e-04],\n",
      "         [-1.4677e-02,  2.8911e-02, -3.7327e-02,  ...,  3.7669e-02,\n",
      "           1.2343e-02,  1.1406e-03],\n",
      "         ...,\n",
      "         [ 4.1059e-03, -2.8472e-02, -1.9606e-02,  ..., -1.0442e-02,\n",
      "          -1.0921e-02, -1.7257e-02],\n",
      "         [ 2.3302e-03, -2.6663e-02, -5.9595e-03,  ...,  1.3540e-02,\n",
      "           7.8044e-03,  2.2301e-02],\n",
      "         [ 1.3815e-02, -2.8477e-02, -3.8000e-02,  ..., -2.5912e-02,\n",
      "           2.6686e-02, -3.3619e-03]],\n",
      "\n",
      "        [[-1.6448e-02,  2.1243e-02, -2.1725e-02,  ...,  2.4007e-02,\n",
      "           1.2125e-03, -3.7975e-02],\n",
      "         [-2.0776e-02,  4.8874e-03, -3.1807e-02,  ...,  3.5451e-02,\n",
      "          -3.0640e-02,  1.1780e-02],\n",
      "         [ 4.1585e-03, -3.0476e-02, -2.2450e-02,  ...,  7.8590e-03,\n",
      "           3.2109e-03, -2.1221e-02],\n",
      "         ...,\n",
      "         [ 3.1024e-03,  1.4105e-02, -3.9140e-02,  ...,  5.7506e-03,\n",
      "           5.5457e-03, -6.7903e-03],\n",
      "         [-1.9476e-02,  1.6019e-02, -3.4255e-02,  ...,  1.9350e-02,\n",
      "           1.2342e-02, -3.3094e-03],\n",
      "         [-2.3542e-04, -2.6106e-02,  2.3038e-02,  ...,  2.7033e-02,\n",
      "           1.9350e-02,  2.3963e-02]],\n",
      "\n",
      "        [[ 3.0378e-02,  1.4125e-02, -1.0541e-02,  ..., -3.2942e-02,\n",
      "          -1.7973e-02,  3.2812e-02],\n",
      "         [-1.2698e-02,  3.0822e-02,  1.9306e-02,  ..., -5.0843e-03,\n",
      "          -2.2588e-02, -6.4381e-03],\n",
      "         [-2.3798e-03, -3.0420e-02,  5.0141e-03,  ..., -1.3595e-02,\n",
      "          -3.6331e-02,  9.2744e-03],\n",
      "         ...,\n",
      "         [-5.4429e-03, -1.8519e-02,  1.8157e-02,  ..., -1.2979e-03,\n",
      "           2.2325e-02, -2.4818e-02],\n",
      "         [-8.5375e-03, -7.3665e-03, -3.4274e-02,  ..., -5.8292e-03,\n",
      "           2.2307e-02, -1.1231e-02],\n",
      "         [ 2.9428e-02,  2.2229e-02,  3.7292e-02,  ...,  6.6530e-03,\n",
      "          -1.7922e-02, -2.0195e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7105e-02,  2.6034e-02,  2.0641e-03,  ..., -2.8863e-02,\n",
      "           1.0769e-02, -2.4036e-02],\n",
      "         [-2.8570e-02,  8.4262e-03,  4.3148e-03,  ...,  3.8349e-02,\n",
      "          -3.2167e-03,  3.3735e-02],\n",
      "         [ 1.1583e-02,  5.4807e-03,  3.3004e-02,  ...,  7.7692e-03,\n",
      "          -3.7218e-02, -3.9071e-02],\n",
      "         ...,\n",
      "         [-1.2389e-02, -1.5068e-02,  6.3354e-03,  ...,  1.5694e-03,\n",
      "          -7.9207e-03,  1.4290e-02],\n",
      "         [-2.2747e-02, -2.2435e-02,  1.0534e-03,  ...,  3.3093e-02,\n",
      "           1.5788e-02, -1.9879e-02],\n",
      "         [ 1.3690e-02,  3.5900e-02,  1.0701e-02,  ...,  3.2137e-03,\n",
      "          -3.2858e-02,  2.6247e-02]],\n",
      "\n",
      "        [[ 2.6087e-02,  3.8009e-02, -3.5834e-02,  ..., -1.6231e-02,\n",
      "           2.7645e-02,  2.7060e-03],\n",
      "         [ 6.0720e-03, -2.4143e-03,  9.7013e-03,  ..., -1.4595e-02,\n",
      "           3.7792e-02, -2.7735e-02],\n",
      "         [ 2.8879e-02, -2.4479e-02, -3.8959e-02,  ...,  7.3620e-03,\n",
      "           1.7355e-02,  4.9037e-03],\n",
      "         ...,\n",
      "         [ 1.4354e-02, -9.2984e-04,  3.5446e-02,  ..., -3.9729e-03,\n",
      "          -1.7688e-04, -3.1179e-02],\n",
      "         [ 2.4973e-02,  2.7169e-02,  2.6691e-02,  ..., -2.2402e-02,\n",
      "           8.9132e-03,  8.7326e-03],\n",
      "         [ 1.5894e-02,  3.8567e-02,  1.5128e-02,  ..., -2.1816e-02,\n",
      "          -1.8118e-02, -3.8326e-02]],\n",
      "\n",
      "        [[ 2.7432e-04, -8.9559e-03,  3.1313e-02,  ..., -1.0242e-02,\n",
      "          -3.4115e-02,  3.3705e-03],\n",
      "         [ 3.1158e-02, -1.7413e-02, -1.9006e-02,  ...,  2.0339e-02,\n",
      "           7.5808e-03,  3.7174e-02],\n",
      "         [-3.6837e-02,  2.9572e-02,  5.2696e-03,  ...,  2.0294e-02,\n",
      "          -7.2498e-03, -2.4136e-02],\n",
      "         ...,\n",
      "         [ 3.8183e-02,  1.1550e-04,  9.8338e-03,  ...,  1.4423e-02,\n",
      "          -2.5642e-02, -2.5442e-02],\n",
      "         [ 3.6587e-02, -3.3784e-02,  2.1130e-02,  ...,  1.8764e-02,\n",
      "           2.8216e-02, -6.3469e-04],\n",
      "         [-1.3282e-03, -1.6124e-02, -3.2757e-02,  ..., -3.3490e-02,\n",
      "           2.7249e-02,  3.4584e-02]]])\n",
      "conv2.bias\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-2.8816, -1.8341, -2.1032, -3.8147,  0.2980,  1.0417, -2.2806,\n",
      "         2.7572, -2.6196, -0.9921,  2.6085,  1.7168,  1.4277,  2.5111,\n",
      "        -0.9372, -3.6216, -1.1881,  0.5489, -3.2618,  1.8411, -1.3675,\n",
      "         3.8070, -0.0568,  2.7512, -1.4580,  2.2219, -0.8959,  3.9033,\n",
      "         0.4649,  3.2188, -0.4121,  0.1620,  2.1826,  0.8102, -1.8645,\n",
      "        -0.2288, -3.6562,  2.1333, -0.8629, -0.0409, -0.2028,  0.3338,\n",
      "         3.2490, -3.4211, -0.6431, -2.2423, -0.4014,  0.0540, -1.0995,\n",
      "         0.0034, -2.8990,  0.7317,  2.6450, -3.1671, -0.7615,  1.2220,\n",
      "         0.5276, -3.7439,  2.8347, -1.5013, -3.1855, -1.0177,  0.1118,\n",
      "         1.5707,  1.3162,  2.3918, -2.8425,  1.1533,  2.3151,  1.8816,\n",
      "         1.0497, -1.3276,  3.0177, -3.8263, -2.4913,  0.9999,  0.5217,\n",
      "        -0.8079, -1.8856,  3.7462,  3.0238,  2.2424,  1.2790,  1.7096,\n",
      "        -2.9269,  3.7278,  1.0587, -1.6082,  3.6856, -2.3764,  1.6954,\n",
      "        -0.2174,  3.1159,  1.9375,  0.3136,  3.6762,  0.6454, -3.3699,\n",
      "        -0.8481, -3.4606,  1.5564,  0.8883, -3.8106,  2.1850,  0.6129,\n",
      "         3.3982, -2.7364, -2.6745, -3.7356, -3.6988,  2.1419, -0.5100,\n",
      "         2.0157, -0.6856,  0.5165,  1.7865,  2.0618, -2.4641, -1.4630,\n",
      "        -1.2282, -1.5272,  1.7925, -3.3984, -3.6110, -2.6769,  2.1230,\n",
      "         2.6283, -2.1489])\n",
      "conv3.weight\n",
      "Parameter containing:\n",
      "tensor([[[-2.5623e-02, -2.4092e-02, -2.6916e-02,  ...,  1.2094e-02,\n",
      "           2.7280e-02, -7.9057e-03],\n",
      "         [-6.0565e-04, -2.7456e-02,  1.3510e-02,  ...,  2.6123e-02,\n",
      "          -2.7351e-02,  2.6736e-02],\n",
      "         [ 1.3585e-02, -1.6850e-03,  1.4512e-02,  ...,  2.2168e-02,\n",
      "          -2.5148e-02,  1.3385e-02],\n",
      "         ...,\n",
      "         [ 8.0802e-04,  2.4697e-02, -1.7423e-02,  ..., -1.6503e-02,\n",
      "           2.2680e-02, -1.1522e-02],\n",
      "         [-2.1854e-03,  2.5636e-02, -2.0048e-02,  ...,  2.3045e-02,\n",
      "           1.5757e-02,  6.0960e-03],\n",
      "         [-8.3993e-03,  1.5406e-02, -1.3277e-02,  ...,  1.8254e-02,\n",
      "           2.4453e-02,  1.7609e-02]],\n",
      "\n",
      "        [[ 3.3151e-03,  8.6765e-03,  8.3441e-03,  ...,  2.4674e-02,\n",
      "          -1.9147e-02,  2.0711e-02],\n",
      "         [-2.0836e-02,  1.3438e-02,  1.4490e-02,  ..., -1.1376e-02,\n",
      "          -4.7074e-03,  5.8916e-03],\n",
      "         [ 1.8472e-02,  1.9836e-02, -2.6305e-02,  ..., -7.4275e-04,\n",
      "          -2.0341e-03,  2.7317e-02],\n",
      "         ...,\n",
      "         [ 6.7732e-03, -6.0103e-03,  6.9261e-03,  ...,  6.5808e-03,\n",
      "          -2.2827e-02, -1.2788e-02],\n",
      "         [ 1.3875e-02, -1.3681e-02,  4.1299e-03,  ..., -5.8500e-03,\n",
      "           1.9719e-02,  7.9893e-03],\n",
      "         [ 3.9547e-03,  3.8113e-04, -2.1770e-02,  ...,  4.2690e-03,\n",
      "          -1.6908e-02, -4.5144e-03]],\n",
      "\n",
      "        [[ 1.4042e-02, -1.7125e-02,  5.8917e-03,  ...,  1.9482e-02,\n",
      "          -9.5764e-04,  1.0809e-02],\n",
      "         [ 1.8028e-03, -8.6253e-03, -3.8407e-03,  ...,  5.8518e-03,\n",
      "           4.5709e-03,  1.7119e-02],\n",
      "         [ 1.3517e-02,  2.0918e-02,  7.0412e-03,  ..., -1.9012e-02,\n",
      "          -4.5316e-03, -1.0118e-02],\n",
      "         ...,\n",
      "         [ 7.9710e-03,  1.7308e-02, -5.8668e-03,  ..., -2.7190e-02,\n",
      "           2.2876e-02, -9.6747e-03],\n",
      "         [ 3.4112e-03, -2.1702e-02, -9.6466e-03,  ...,  1.7545e-02,\n",
      "           3.6767e-03, -4.8734e-03],\n",
      "         [ 2.0409e-02,  1.2096e-02, -4.4311e-03,  ...,  2.4292e-02,\n",
      "           1.6984e-02,  9.5972e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6271e-02, -2.5359e-02, -2.6522e-02,  ...,  6.5152e-03,\n",
      "          -2.2339e-02,  5.1762e-04],\n",
      "         [-1.7641e-02,  9.9332e-03,  7.7632e-03,  ..., -2.4576e-02,\n",
      "          -2.1035e-02, -1.1736e-03],\n",
      "         [ 7.9770e-04,  5.7861e-03,  8.7491e-03,  ...,  6.2611e-03,\n",
      "           1.4553e-02,  1.8493e-02],\n",
      "         ...,\n",
      "         [-2.4532e-02, -3.3276e-03,  1.4747e-02,  ...,  1.5982e-02,\n",
      "          -2.1921e-02,  1.0665e-02],\n",
      "         [-9.4601e-03, -2.5187e-02, -5.7279e-03,  ...,  1.2814e-03,\n",
      "          -2.2657e-02,  3.0251e-03],\n",
      "         [-9.6863e-03, -5.4497e-04, -2.3220e-02,  ...,  1.0280e-02,\n",
      "          -1.0131e-02,  1.8928e-02]],\n",
      "\n",
      "        [[ 5.1040e-03, -1.0683e-02, -1.0129e-03,  ..., -4.6013e-03,\n",
      "          -2.2726e-02, -1.4804e-02],\n",
      "         [-1.5930e-02,  2.7877e-02, -2.2536e-02,  ...,  1.4707e-02,\n",
      "           7.4417e-03,  4.3244e-03],\n",
      "         [ 7.0719e-03, -6.9478e-03,  2.4885e-02,  ..., -2.6516e-02,\n",
      "           2.6265e-02, -2.0289e-02],\n",
      "         ...,\n",
      "         [-5.4826e-03, -2.1040e-02, -1.2951e-02,  ..., -3.4365e-03,\n",
      "          -1.1698e-02, -1.3697e-02],\n",
      "         [ 1.8799e-02, -7.0180e-04,  4.1190e-03,  ..., -1.0340e-02,\n",
      "          -1.2650e-02,  7.4058e-03],\n",
      "         [-1.6808e-02,  2.3148e-02,  3.7528e-03,  ...,  1.5574e-02,\n",
      "           9.3554e-03, -1.8234e-02]],\n",
      "\n",
      "        [[-2.4994e-02, -2.3215e-02, -4.9268e-03,  ...,  2.1170e-02,\n",
      "          -2.5416e-02, -2.3103e-02],\n",
      "         [ 2.2354e-02, -2.2499e-03, -1.7764e-02,  ...,  2.4036e-02,\n",
      "          -5.7186e-03, -2.5575e-02],\n",
      "         [-2.3156e-02,  3.6802e-04, -1.6465e-02,  ..., -1.0664e-02,\n",
      "          -1.5524e-02, -1.3875e-02],\n",
      "         ...,\n",
      "         [-1.2418e-02, -1.5632e-02, -2.4858e-02,  ..., -8.0805e-03,\n",
      "          -1.1652e-02,  1.0441e-02],\n",
      "         [ 2.2982e-02, -1.7628e-02,  1.6513e-03,  ...,  6.2504e-03,\n",
      "           1.3643e-03,  1.0361e-02],\n",
      "         [ 1.1008e-02, -2.3000e-02,  5.7763e-03,  ..., -1.7416e-02,\n",
      "           1.4534e-02, -2.6255e-02]]])\n",
      "conv3.bias\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [ 0.7437, -1.6538, -1.7203, -0.3228, -0.2950, -1.4150,  2.2547,\n",
      "         0.0840,  1.1017,  2.1385, -1.6748, -0.1388, -1.9378, -1.4298,\n",
      "         1.4589,  2.7138,  1.8417, -2.2360, -1.1747, -1.5417,  1.7160,\n",
      "         0.1267,  2.6056, -2.6681, -1.9508,  2.1259, -0.0658, -1.8058,\n",
      "        -1.6501, -1.8862,  0.5587,  2.6522,  0.9858,  0.2444,  2.1884,\n",
      "        -1.8166,  0.9702,  1.0769,  2.7274, -2.5074,  1.7147, -2.2648,\n",
      "         1.1713, -2.1209,  1.7334,  0.8179,  1.4691,  2.4559, -1.2331,\n",
      "         0.9967,  1.7054, -2.1716,  2.7619,  2.5392, -1.4224,  1.7972,\n",
      "         2.3417, -1.3600, -2.3893,  0.8676,  1.8227,  1.5500,  1.3767,\n",
      "         0.4759, -0.7644,  0.2139, -0.9129,  2.1037,  0.1137, -0.7658,\n",
      "         2.4838,  2.2316, -0.6145, -0.4176,  1.9377, -2.6651, -2.5656,\n",
      "        -1.2160, -1.0474,  2.3098, -1.3761,  1.4516, -2.7259, -0.4007,\n",
      "         0.9578, -1.7738,  1.8356, -1.6943, -0.5359,  0.5918,  0.7051,\n",
      "         1.0284, -1.9105, -0.5181, -0.7146, -0.7948,  2.7205,  0.5239,\n",
      "         1.8389, -1.6417,  1.2720, -2.5947,  2.7049,  0.6664, -2.4891,\n",
      "        -1.4866,  0.2054, -2.2458, -1.2103,  0.6421, -2.0184, -2.7910,\n",
      "        -1.9976, -0.0934,  1.9820,  2.1351, -2.3669, -1.4398, -1.0359,\n",
      "         2.0857, -2.5466,  2.5812, -2.5678,  2.2163, -1.8821,  0.1031,\n",
      "        -2.1812,  2.4086, -2.3490,  0.7766,  1.4612,  2.7329, -1.1224,\n",
      "         0.2895,  1.4069,  1.3785,  0.1670, -0.4303, -1.4667, -0.8883,\n",
      "        -2.5563,  0.6736,  1.5102, -2.1091, -0.0210,  0.7662,  1.1268,\n",
      "        -1.8590,  2.1908,  1.3472, -2.5509, -1.2674, -0.8902,  2.5401,\n",
      "        -1.6054, -0.2467, -1.9677,  0.7643, -1.7282, -0.9895,  2.0618,\n",
      "        -1.4878,  0.5918, -1.3407,  0.5282, -0.1070, -2.7617, -1.0018,\n",
      "        -0.8749, -1.0362, -0.5249,  1.6795,  0.5290, -1.4780,  2.5986,\n",
      "         1.2024,  1.9000, -0.4529, -1.3716, -2.2944,  1.7146, -1.0541,\n",
      "        -2.0664, -1.5940, -1.7125, -1.9355,  1.8765, -0.2667,  0.7769,\n",
      "         2.6304, -0.2647,  2.3139,  1.6777,  0.4271, -2.5266, -1.1256,\n",
      "         0.9674, -1.3926, -2.1240,  1.5452, -1.0105, -0.4051,  0.2461,\n",
      "         2.1274, -1.4275,  1.5417,  2.5163, -0.9134, -0.0341, -1.7563,\n",
      "        -2.2448, -2.5131, -1.5004,  2.4337,  2.2275,  2.3554,  0.9562,\n",
      "        -0.7029,  1.0705, -0.2065, -1.1754, -1.1159, -0.2252,  1.0170,\n",
      "         1.2677,  2.7608,  0.9995,  1.2729, -0.1309, -0.2205,  1.7273,\n",
      "        -2.2022,  0.9084, -1.3953,  1.8019,  1.1270,  2.5009, -0.7971,\n",
      "        -0.2791,  1.5679, -2.4547,  0.2996,  1.6063,  2.1401,  0.9616,\n",
      "        -0.0505,  0.9395, -2.6685,  0.2237,  1.8040,  2.4895, -2.6229,\n",
      "        -2.5600, -1.3839,  1.5246, -0.2832])\n",
      "conv4.weight\n",
      "Parameter containing:\n",
      "tensor([[[ 5.4825e-03,  1.6498e-02, -1.7715e-03,  ..., -1.6135e-02,\n",
      "          -5.8865e-05,  2.5699e-03],\n",
      "         [ 8.4316e-03,  9.3304e-03,  1.6789e-02,  ..., -3.4934e-03,\n",
      "          -1.2095e-02,  1.5779e-02],\n",
      "         [ 1.1398e-02,  1.0655e-02,  3.8887e-03,  ...,  1.3161e-02,\n",
      "          -3.3805e-03, -1.7627e-02],\n",
      "         ...,\n",
      "         [-1.0714e-02, -7.5572e-03,  1.2805e-02,  ...,  2.9236e-03,\n",
      "           7.3645e-03,  9.1425e-04],\n",
      "         [ 1.7273e-02, -1.2415e-02, -1.9197e-02,  ..., -5.4816e-03,\n",
      "           1.6333e-02, -1.7317e-02],\n",
      "         [-1.7807e-02, -5.9207e-03,  1.2860e-02,  ...,  1.0157e-03,\n",
      "          -1.1965e-02, -9.7177e-03]],\n",
      "\n",
      "        [[-1.9583e-02, -1.0195e-02,  2.0030e-03,  ...,  1.1732e-02,\n",
      "          -9.7893e-03,  1.3739e-02],\n",
      "         [-1.2208e-02, -9.3841e-03,  1.9642e-02,  ..., -1.4193e-02,\n",
      "          -7.1622e-03, -1.5555e-02],\n",
      "         [ 9.4088e-05, -4.0102e-03, -1.0182e-02,  ..., -8.9950e-03,\n",
      "          -2.2487e-03,  8.1272e-04],\n",
      "         ...,\n",
      "         [ 1.7449e-02, -1.2202e-02, -5.9308e-03,  ...,  5.5406e-03,\n",
      "           1.7011e-02, -1.9062e-02],\n",
      "         [-1.7682e-02, -6.1570e-03,  1.5719e-02,  ..., -1.0127e-02,\n",
      "           1.2497e-02,  1.1370e-03],\n",
      "         [ 1.9844e-03,  1.2426e-02,  1.1949e-02,  ...,  1.0645e-02,\n",
      "          -1.8331e-02, -1.9189e-02]],\n",
      "\n",
      "        [[ 1.2525e-02,  1.8447e-02, -1.1342e-03,  ..., -1.3906e-02,\n",
      "           3.5072e-03,  2.8582e-03],\n",
      "         [ 1.0171e-02,  1.8352e-02, -1.2125e-02,  ...,  1.6279e-02,\n",
      "          -1.1732e-02,  5.8273e-03],\n",
      "         [-1.1042e-02,  1.2684e-02,  1.3550e-02,  ...,  6.8326e-03,\n",
      "           1.8689e-02,  1.9660e-02],\n",
      "         ...,\n",
      "         [ 1.4209e-02, -1.7068e-03,  4.3963e-03,  ...,  6.6089e-03,\n",
      "           1.4565e-02,  1.4206e-02],\n",
      "         [ 9.4440e-03,  6.3244e-03, -3.6347e-03,  ..., -1.5226e-02,\n",
      "          -1.1779e-02, -5.6066e-03],\n",
      "         [ 7.0991e-03,  1.6730e-03, -1.7792e-02,  ..., -1.5896e-02,\n",
      "          -7.9858e-03, -1.3978e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.2434e-03,  5.2851e-03,  5.0925e-03,  ..., -1.0521e-02,\n",
      "           1.4167e-02,  1.2451e-02],\n",
      "         [-1.5128e-02, -1.4012e-02, -1.5558e-03,  ..., -7.2233e-03,\n",
      "           1.1597e-02, -1.2565e-03],\n",
      "         [-1.4824e-02,  8.1949e-03,  1.0952e-03,  ..., -1.8144e-02,\n",
      "          -1.3975e-03, -1.7453e-02],\n",
      "         ...,\n",
      "         [-1.0455e-02, -6.9911e-03, -5.0103e-03,  ...,  1.0185e-02,\n",
      "           1.0701e-03, -1.2632e-02],\n",
      "         [ 5.1384e-03,  1.7922e-02,  7.0674e-04,  ...,  9.3767e-04,\n",
      "          -1.4973e-02,  1.9752e-02],\n",
      "         [-3.4498e-03,  1.8078e-02, -5.2909e-03,  ...,  7.7329e-03,\n",
      "           1.0671e-02,  1.7550e-02]],\n",
      "\n",
      "        [[ 8.4113e-03, -2.4859e-03, -1.6493e-02,  ...,  1.7236e-02,\n",
      "           1.9083e-03, -1.6490e-02],\n",
      "         [ 1.0104e-02,  1.1134e-02,  3.9100e-03,  ..., -3.3451e-04,\n",
      "          -1.5046e-02,  1.8318e-02],\n",
      "         [-2.4033e-03,  1.1960e-02, -6.4501e-03,  ...,  6.4278e-05,\n",
      "           7.7231e-03, -7.3953e-03],\n",
      "         ...,\n",
      "         [-1.0523e-02,  1.9264e-02, -1.8499e-02,  ..., -1.9574e-02,\n",
      "          -1.9557e-02,  2.2688e-03],\n",
      "         [ 9.9235e-03, -7.0217e-03,  1.7554e-02,  ...,  2.1645e-03,\n",
      "           8.7709e-03,  4.3944e-03],\n",
      "         [ 2.3912e-03, -1.1657e-02,  3.0203e-04,  ...,  1.4875e-02,\n",
      "          -1.2269e-02,  1.4568e-02]],\n",
      "\n",
      "        [[ 5.8177e-03,  9.0336e-04,  1.5000e-02,  ...,  1.6568e-02,\n",
      "          -4.7072e-03,  4.1153e-03],\n",
      "         [-1.0076e-02, -9.9055e-03, -5.5521e-03,  ...,  3.0155e-03,\n",
      "           1.0497e-02,  3.0799e-04],\n",
      "         [ 1.6164e-02,  1.1037e-02,  2.2539e-03,  ..., -1.7685e-02,\n",
      "           1.8941e-02, -2.8920e-03],\n",
      "         ...,\n",
      "         [ 1.6994e-02,  1.9381e-03, -6.6255e-04,  ..., -1.6884e-02,\n",
      "           2.1113e-03, -9.6150e-03],\n",
      "         [-1.3184e-02, -1.3984e-02, -1.2403e-02,  ...,  2.9799e-03,\n",
      "           1.7834e-03,  1.2200e-02],\n",
      "         [ 1.3973e-02,  1.7670e-02, -1.6013e-02,  ..., -1.7224e-02,\n",
      "          -3.7790e-03,  1.3908e-02]]])\n",
      "conv4.bias\n",
      "Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [ 0.9166,  0.5403,  0.4342,  1.8720, -1.0758, -1.8101, -1.6969,\n",
      "        -1.9341, -0.2428, -1.4392, -1.1379,  1.7882, -1.1001,  0.8142,\n",
      "         0.5682, -1.0858, -0.4744, -1.9324, -1.5094,  0.8508, -1.1729,\n",
      "        -1.1927,  0.3865, -1.2511,  1.2779, -0.1317,  1.0597,  1.3054,\n",
      "         1.2985,  0.0318,  0.7613, -1.1013,  0.8402,  0.7820, -0.1605,\n",
      "        -1.4863, -1.1442, -0.3187,  0.0024, -1.4950,  1.5457,  0.2605,\n",
      "         0.5929,  1.1006, -1.4439,  1.3287,  0.0245,  1.6003,  1.8647,\n",
      "         0.3754, -0.0022,  0.8849, -0.6436,  0.6885, -0.1066,  1.8114,\n",
      "        -0.4714,  1.7808, -0.7921,  1.9585,  0.6410,  1.3222, -0.8475,\n",
      "        -1.7550,  1.4467, -0.9643,  0.8096,  0.6745, -0.6469, -1.6521,\n",
      "        -0.3467, -1.0548,  1.0314, -0.9575,  1.8584,  1.1710, -0.2606,\n",
      "         1.5777,  1.7371,  1.4846,  0.6223,  1.7033,  0.8422, -1.7488,\n",
      "         1.6239, -1.2297, -1.6426,  0.6406,  0.5092, -1.0374,  1.6225,\n",
      "         0.9863,  0.3385,  0.2337, -1.6346, -0.8194,  1.0919, -0.2496,\n",
      "        -0.0538,  1.6824, -0.3071, -0.4175,  0.4870, -0.2779,  0.9505,\n",
      "        -0.5023, -1.4765,  0.3736,  0.2314, -1.5015, -1.7895,  0.6549,\n",
      "        -0.4507,  0.8015,  1.9401, -1.6816, -1.1029, -0.8572, -1.3942,\n",
      "         0.5061, -1.8014, -1.1004,  0.4250,  0.4380, -1.7723,  1.0108,\n",
      "        -0.1257,  1.2420,  1.5605,  1.5803,  1.2777, -0.9182,  0.2790,\n",
      "         1.2227, -1.3573, -1.7925,  0.9464, -1.2073, -0.1874, -1.3877,\n",
      "         0.8574,  1.9247, -0.0943,  1.1491,  1.2218, -1.9183, -1.4375,\n",
      "         1.7587,  0.9677, -1.4470,  1.6491, -1.0102,  0.3940,  0.4971,\n",
      "        -1.6367,  0.9612,  0.8036,  1.0175, -1.6714, -1.3238, -0.8608,\n",
      "         1.9464,  1.8350,  0.1805, -0.5979, -0.4260,  1.2828,  0.4359,\n",
      "        -0.9860, -0.7155, -1.7290, -1.7669,  0.7424,  1.1578,  1.6240,\n",
      "         0.3887,  1.3494,  0.5926, -0.3932,  0.5827,  0.7315, -0.9417,\n",
      "         1.2480, -1.2112,  1.7937,  1.3166,  1.0611, -0.5425,  1.4979,\n",
      "        -0.2204, -1.6330,  0.6713,  0.4465, -1.4272, -0.7536, -1.6599,\n",
      "         1.0206,  0.7282, -0.7924,  1.7574,  1.5298, -1.1408,  0.0652,\n",
      "        -1.3694, -0.9513, -1.2478, -1.6676, -0.9071,  0.0162, -0.0739,\n",
      "        -0.8611,  0.0802,  1.3907, -1.3241, -0.1398,  0.2644, -1.7529,\n",
      "        -0.7774,  1.7433,  1.2593,  0.1456,  0.7493,  0.5046, -1.4836,\n",
      "        -1.8703,  0.8058,  1.2094, -1.4205,  0.4752,  1.6797,  0.0427,\n",
      "        -0.5042,  1.8514,  0.5645,  1.8081,  0.1084, -0.9866, -0.7135,\n",
      "         0.9568, -1.0392, -1.7620, -1.7335,  1.0234,  0.1493,  0.7017,\n",
      "         0.6440, -1.8716, -1.8878,  0.0586,  0.6749, -0.0660,  1.7644,\n",
      "        -1.1412, -0.4246,  0.6496,  1.8828])\n"
     ]
    }
   ],
   "source": [
    "for tag, value in posenet.named_parameters():\n",
    "    print (tag)\n",
    "    print (value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
